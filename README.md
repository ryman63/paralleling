# Отчёт по лабораторным работам №1, №3, №4, №5 и №6

## Титульный лист

**Учебное заведение:** ИТМО
**Факультет:** ФПИ и КТ
**Дисциплина:** «Параллельные вычисления»
**Тема:** Реализация и исследование последовательных и параллельных версий вычислительного конвейера (Generate → Map → Merge → Sort → Reduce).

**Студент:** Самойлов Дмитрий Сергеевич, P4216
**Преподаватель:** Жданов Андрей Дмитриевич

---

## Содержание

1. Титульный лист
2. Характеристика оборудования и программного обеспечения
3. Краткое описание решаемой задачи
4. Лабораторная работа №1
5. Лабораторная работа №3
6. Лабораторная работа №4
7. Лабораторная работа №5
8. Лабораторная работа №6
9. Общие выводы

---

## 2. Характеристика оборудования

Все эксперименты выполнялись на персональном компьютере со следующей конфигурацией:

Процессор: AMD Ryzen 5 5600X
Процессор содержит 6 физических ядер и поддерживает 12 логических потоков. Базовая тактовая частота — 3.7 ГГц, максимальная частота в режиме Boost — до 4.6 ГГц.

Видеокарта: AMD Radeon RX 5700 XT
Видеокарта использовалась для выполнения вычислений на стороне устройства OpenCL в лабораторной работе №6. Архитектура GPU позволяет эффективно выполнять массово-параллельные операции над большими массивами данных.

Данная конфигурация позволяет на практике исследовать масштабируемость алгоритмов как на CPU, так и на GPU, а также сравнить эффективность различных моделей параллельных вычислений.

---

## 3. Краткое описание решаемой задачи

В рамках серии лабораторных работ реализуется вычислительный конвейер, состоящий из следующих этапов:

* генерация входных данных (Generate);
* локальное преобразование элементов (Map);
* попарное объединение промежуточных результатов (Merge);
* сортировка (Sort);
* свёртка данных с получением итоговой величины *X* (Reduce).

Основная цель работ — последовательно перейти от полностью последовательной реализации к различным вариантам параллельных вычислений, сравнить их между собой и оценить выигрыш по времени выполнения, а также устойчивость результатов измерений.

---

## 4. Лабораторная работа №1 — эталонная последовательная реализация

### Краткое описание

В первой лабораторной работе была реализована полностью последовательная версия вычислительного конвейера. Она включает генерацию данных, все этапы обработки, собственную реализацию сортировки и финальную операцию reduce.

Данная версия используется как эталон для проверки корректности вычислений и как базовая точка сравнения при оценке параллельных реализаций.

### Выводы

Последовательная реализация корректно вычисляет итоговую величину *X* и демонстрирует стабильное поведение при повторных запусках. Для получения воспроизводимых результатов измерений я выполнял несколько прогонов и использовал прогревочные запуски, чтобы исключить влияние одноразовых накладных расходов.

Для проведения экспериментов для каждой лабораторной работы были написаны вспомогательные **Python-скрипты**, автоматизирующие запуск программы с различными параметрами. Скрипты собирали выходные данные серии прогонов и на их основе строили графики, что позволило наглядно сравнивать результаты и упростило анализ производительности.

Профилирование показало, какие этапы конвейера занимают наибольшую долю времени выполнения. Эти участки в дальнейшем рассматривались как основные кандидаты для оптимизации и распараллеливания.

**Сборка:**

```
gcc <source.c> -O3 -o <executable>
```

---

## 5. Лабораторная работа №3 — распараллеливание циклов с использованием директив

### Краткое описание

В третьей лабораторной работе были распараллелены вычислительные циклы с использованием директив (OpenMP). Для оценки эффективности параллелизма использовались Python-скрипты, которые выполняли серию запусков программы и строили графики времени выполнения.

### Выводы

По результатам экспериментов прироста производительности получить не удалось. Накладные расходы на создание, управление и синхронизацию потоков оказались сопоставимы или превышали выигрыш от распараллеливания, что привело к увеличению общего времени выполнения по сравнению с последовательной версией. Данный результат хорошо виден на построенных графиках и подчёркивает важность учёта накладных расходов при параллелизации.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -o <executable>
```

---

## 6. Лабораторная работа №4 — доверительные интервалы и параллельная сортировка

### Краткое описание

Четвёртая лабораторная работа была посвящена корректной организации измерений и реализации параллельной сортировки. Для автоматизации экспериментов также использовались Python-скрипты, выполнявшие серию прогонов и строившие графики производительности.

### Выводы

В данной работе был получен существенный прирост производительности — до **20 раз** по сравнению с последовательной реализацией. Это стало возможным за счёт распараллеливания наиболее узкого места (bottleneck) вычислительного конвейера, которое доминировало по времени выполнения. Построенные графики наглядно демонстрируют масштабируемость алгоритма и подтверждают, что максимальный эффект достигается при оптимизации критических участков.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -o <executable>
```

---

## 7. Лабораторная работа №5 — использование POSIX Threads

### Краткое описание

В пятой лабораторной работе ключевые участки конвейера были реализованы с использованием библиотеки POSIX threads. Параллельная сортировка выполнялась путём разбиения данных на чанки, а также был реализован потокобезопасный вывод прогресса выполнения.

### Выводы

Использование POSIX threads дало больше гибкости и контроля над распределением работы между потоками по сравнению с директивами. Простая схема деления данных на равные чанки хорошо работает при равномерной нагрузке, однако для более сложных сценариев имеет смысл применять динамические стратегии распределения задач.

При увеличении числа потоков заметно возрастает влияние накладных расходов на синхронизацию, поэтому для повышения масштабируемости важно минимизировать критические секции в наиболее нагруженных участках кода.

Сравнение OpenMP и POSIX threads не показало сильной разницы в производительности.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -pthread -o <executable>
```

---

## 8. Лабораторная работа №6 — использование OpenCL

### Краткое описание

В шестой лабораторной работе была реализована гибридная версия вычислительного конвейера с использованием технологии OpenCL. Часть этапов обработки данных (Map и Merge) была перенесена на вычислительное устройство (GPU), тогда как генерация данных, сортировка и операция Reduce выполнялись на стороне CPU.

Программа использует модель host–device, где:

- host (CPU) отвечает за:

    - генерацию входных данных;

    - запуск OpenCL-ядер;

    - синхронизацию выполнения;

    - сортировку результатов с использованием POSIX threads;

    - финальную операцию Reduce;

- device (GPU) выполняет вычислительно нагруженные этапы над массивами данных.

### Архитектура OpenCL-части

В рамках одной итерации вычислений последовательно запускаются четыре OpenCL-ядра:

1. compute_M1.
Параллельно обрабатывает массив M1, выполняя локальные вычисления для каждого элемента.

2. compute_M2.
Выполняет копирование и предварительную обработку массива M2 с использованием вспомогательного буфера copy.

3. compute_M2_final.
Завершает этап Map, используя данные из обоих буферов.

4. merge.
Реализует этап Merge, объединяя результаты обработки массивов M1 и M2.

### Выводы

Использование OpenCL позволило продемонстрировать потенциал ускорения вычислительного конвейера за счёт переноса наиболее параллелизуемых этапов на GPU. На больших объёмах данных выигрыш от массового параллелизма становится заметным, однако при малых размерах входных массивов накладные расходы на инициализацию OpenCL и передачу данных между host и device могут нивелировать преимущества.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -pthread -lOpenCL -o <executable>
```

---

## 9. Общие выводы
В ходе выполнения всех лабораторных работ было подтверждено, что последовательная реализация необходима как эталон корректности и база для сравнений. Локальные оптимизации и векторизация позволяют получить быстрый выигрыш без существенного усложнения кода. Директивы OpenMP удобны для экспериментов и быстрого внедрения параллелизма, POSIX threads предоставляют полный контроль, но требуют более сложной реализации, а OpenCL обеспечивает наибольший потенциал ускорения при больших объёмах данных и наличии подходящего устройства.

---

**Запуск:**

```
<executable> <N> <THREADS>
```
