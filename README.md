# Отчёт по лабораторным работам №1, №3, №4, №5 и №6

## Титульный лист

**Учебное заведение:** ИТМО
**Факультет:** ФПИ и КТ
**Дисциплина:** «Параллельные вычисления»
**Тема:** Реализация и исследование последовательных и параллельных версий вычислительного конвейера (Generate → Map → Merge → Sort → Reduce).

**Студент:** Самойлов Дмитрий Сергеевич, P4216
**Преподаватель:** Жданов Андрей Дмитриевич

---

## Содержание

1. Титульный лист
2. Характеристика оборудования и программного обеспечения
3. Краткое описание решаемой задачи
4. Лабораторная работа №1
5. Лабораторная работа №3
6. Лабораторная работа №4
7. Лабораторная работа №5
8. Лабораторная работа №6
9. Общие выводы

---

## 2. Характеристика оборудования и программного обеспечения

Все эксперименты выполнялись на персональном компьютере с процессором **AMD Ryzen 5 5600X**. Процессор содержит 6 физических ядер и поддерживает 12 логических потоков, базовая тактовая частота составляет 3.7 ГГц, максимальная частота в режиме Boost — до 4.6 ГГц.

Данная конфигурация позволяет на практике исследовать масштабируемость алгоритмов и влияние числа потоков на производительность.

---

## 3. Краткое описание решаемой задачи

В рамках серии лабораторных работ реализуется вычислительный конвейер, состоящий из следующих этапов:

* генерация входных данных (Generate);
* локальное преобразование элементов (Map);
* попарное объединение промежуточных результатов (Merge);
* сортировка (Sort);
* свёртка данных с получением итоговой величины *X* (Reduce).

Основная цель работ — последовательно перейти от полностью последовательной реализации к различным вариантам параллельных вычислений, сравнить их между собой и оценить выигрыш по времени выполнения, а также устойчивость результатов измерений.

---

## 4. Лабораторная работа №1 — эталонная последовательная реализация

### Краткое описание

В первой лабораторной работе была реализована полностью последовательная версия вычислительного конвейера. Она включает генерацию данных, все этапы обработки, собственную реализацию сортировки и финальную операцию reduce.

Данная версия используется как эталон для проверки корректности вычислений и как базовая точка сравнения при оценке параллельных реализаций.

### Выводы

Последовательная реализация корректно вычисляет итоговую величину *X* и демонстрирует стабильное поведение при повторных запусках. Для получения воспроизводимых результатов измерений я выполнял несколько прогонов и использовал прогревочные запуски, чтобы исключить влияние одноразовых накладных расходов.

Для проведения экспериментов для каждой лабораторной работы были написаны вспомогательные **Python-скрипты**, автоматизирующие запуск программы с различными параметрами. Скрипты собирали выходные данные серии прогонов и на их основе строили графики, что позволило наглядно сравнивать результаты и упростило анализ производительности.

Профилирование показало, какие этапы конвейера занимают наибольшую долю времени выполнения. Эти участки в дальнейшем рассматривались как основные кандидаты для оптимизации и распараллеливания.

**Сборка:**

```
gcc <source.c> -O3 -o <executable>
```

---

## 5. Лабораторная работа №3 — распараллеливание циклов с использованием директив

### Краткое описание

В третьей лабораторной работе были распараллелены вычислительные циклы с использованием директив (OpenMP). Для оценки эффективности параллелизма использовались Python-скрипты, которые выполняли серию запусков программы и строили графики времени выполнения.

### Выводы

По результатам экспериментов прироста производительности получить не удалось. Накладные расходы на создание, управление и синхронизацию потоков оказались сопоставимы или превышали выигрыш от распараллеливания, что привело к увеличению общего времени выполнения по сравнению с последовательной версией. Данный результат хорошо виден на построенных графиках и подчёркивает важность учёта накладных расходов при параллелизации.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -o <executable>
```

---

## 6. Лабораторная работа №4 — доверительные интервалы и параллельная сортировка

### Краткое описание

Четвёртая лабораторная работа была посвящена корректной организации измерений и реализации параллельной сортировки. Для автоматизации экспериментов также использовались Python-скрипты, выполнявшие серию прогонов и строившие графики производительности.

### Выводы

В данной работе был получен существенный прирост производительности — до **16 раз** по сравнению с последовательной реализацией. Это стало возможным за счёт распараллеливания наиболее узкого места (bottleneck) вычислительного конвейера, которое доминировало по времени выполнения. Построенные графики наглядно демонстрируют масштабируемость алгоритма и подтверждают, что максимальный эффект достигается при оптимизации критических участков.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -o <executable>
```

---

## 7. Лабораторная работа №5 — использование POSIX Threads

### Краткое описание

В пятой лабораторной работе ключевые участки конвейера были реализованы с использованием библиотеки POSIX threads. Параллельная сортировка выполнялась путём разбиения данных на чанки, а также был реализован потокобезопасный вывод прогресса выполнения.

### Выводы

Использование POSIX threads дало больше гибкости и контроля над распределением работы между потоками по сравнению с директивами. Простая схема деления данных на равные чанки хорошо работает при равномерной нагрузке, однако для более сложных сценариев имеет смысл применять динамические стратегии распределения задач.

При увеличении числа потоков заметно возрастает влияние накладных расходов на синхронизацию, поэтому для повышения масштабируемости важно минимизировать критические секции в наиболее нагруженных участках кода.

Сравнение OpenMP и POSIX threads не показало сильной разницы в производительности.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -pthread -o <executable>
```

---

## 8. Лабораторная работа №6 — использование OpenCL

### Краткое описание

В шестой лабораторной работе отдельные этапы вычислительного конвейера были перенесены на устройство OpenCL (CPU/GPU). Были реализованы и отлажены OpenCL-ядра, а также организована передача данных между host и device.

### Выводы

Применение OpenCL показало высокий потенциал ускорения при больших объёмах входных данных и корректной организации передачи буферов. При небольших размерах задач накладные расходы на копирование данных между host и device зачастую перекрывают выигрыш от параллельных вычислений.

**Сборка:**

```
gcc <source.c> -O3 -fopenmp -pthread -lOpenCL -o <executable>
```

---

## 9. Общие выводы
В ходе выполнения всех лабораторных работ было подтверждено, что последовательная реализация необходима как эталон корректности и база для сравнений. Локальные оптимизации и векторизация позволяют получить быстрый выигрыш без существенного усложнения кода. Директивы OpenMP удобны для экспериментов и быстрого внедрения параллелизма, POSIX threads предоставляют полный контроль, но требуют более сложной реализации, а OpenCL обеспечивает наибольший потенциал ускорения при больших объёмах данных и наличии подходящего устройства.

---

**Запуск:**

```
<executable> <N> <THREADS>
```
